{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ab319b-1856-4f6c-b29d-af7c399c963a",
   "metadata": {},
   "source": [
    "<h1><center>Data Extraction from PhonePe Pulse Repo<center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646a2bd",
   "metadata": {},
   "source": [
    "<b>Importing Libraries<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51da4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import mysql.connector as sql\n",
    "import os\n",
    "import git\n",
    "from pathlib import  Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de61e5",
   "metadata": {},
   "source": [
    "<b>Clone Git Repository<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795cbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Specify the directories\n",
    "# git_url = 'https://github.com/PhonePe/pulse.git'\n",
    "# cloned_directory = 'data/pulse_data'\n",
    "\n",
    "# #Clone\n",
    "# git.Repo.clone_from(git_url, cloned_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ec085",
   "metadata": {},
   "source": [
    "<h1><center>Data Processing</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24a088",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Goto the main entry point of the program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4af8eee",
   "metadata": {},
   "source": [
    "<b>Declaring all the directories and the data dictionaries</b>\n",
    "\n",
    "Here we are declaring all the directories from which we have to extract the data\n",
    "and the data dictionaries where we will save the data to change to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cdac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directories\n",
    "agg_insurance_dir = 'data/pulse_data/data/aggregated/insurance/country/india/state'\n",
    "agg_transaction_dir = 'data/pulse_data/data/aggregated/transaction/country/india/state'\n",
    "agg_user_dir = 'data/pulse_data/data/aggregated/user/country/india/state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba499969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Dictionaries\n",
    "agg_insurance_data = {'States':[],'Years':[],'Quarters':[],'Total_Policies':[],'Total_Amount':[]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e6435",
   "metadata": {},
   "source": [
    "<b>Defining necessary functions</b>\n",
    "\n",
    "1. read_json - This function takes a json file as parameter and returns the json data\n",
    "\n",
    "2. save_to_csv - This function takes a dictionary and name of the file as parameter and converts the dictionary to a pandas dataframe and dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582621a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read JSON\n",
    "def read_json(path):\n",
    "    return pd.read_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083461ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataframe to csv file\n",
    "def save_to_csv(file_dict,filename):\n",
    "    #Convert the dictionary to dataframe\n",
    "    df = pd.DataFrame(file_dict)\n",
    "    df.to_csv(f'data/csv_data/{filename}',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41806e2e",
   "metadata": {},
   "source": [
    "<b>Extraction Functions</b>\n",
    "\n",
    "This block contains all the functions that extracts data from the JSON file and saves it to a dictionary.\n",
    "Parameters are state, year, quarter and the json data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc7c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract aggregated insurance\n",
    "def agg_insurance(state,year,quarter,year_json):\n",
    "    data = year_json['data']['transactionData']\n",
    "    if(data):\n",
    "        for i in data:\n",
    "            count = i['paymentInstruments'][0]['count']\n",
    "            amount = i['paymentInstruments'][0]['amount']\n",
    "            \n",
    "            if '-' in state:\n",
    "                state = state.replace('-',' ')\n",
    "            agg_insurance_data['States'] .append(state.capitalize())\n",
    "            \n",
    "            agg_insurance_data['Years'].append(year)\n",
    "            agg_insurance_data['Quarters'].append(quarter)\n",
    "            agg_insurance_data['Total_Policies'].append(count)\n",
    "            agg_insurance_data['Total_Amount'].append(amount)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2373d6",
   "metadata": {},
   "source": [
    "<b>Accumulated extraction functions</b>\n",
    "\n",
    "This function makes a dictionary of the extraction functions so that it becomes easier to call each extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bff7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to accumulate all the functions and call respective function\n",
    "\n",
    "#Check Invalid\n",
    "def invalid_extraction_op():\n",
    "    raise Exception(\"Invalid operation\") \n",
    "\n",
    "#Call the respective functions\n",
    "def perform_extraction(state,year,quarter,operation,year_json):\n",
    "    etl_functions = {\n",
    "    \"agg_insurance\": agg_insurance,\n",
    "    }\n",
    "\n",
    "    chosen_extraction_function = etl_functions.get(operation, invalid_extraction_op)\n",
    "\n",
    "    return chosen_extraction_function(state,year,quarter,year_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3629cc61",
   "metadata": {},
   "source": [
    "<b>Function to iterate through the directories</b>\n",
    "\n",
    "This function takes a directory path and the extraction function name as parameter.\n",
    "It goes through the directories and sends the JSON file for extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b38c4e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to iterate and get the JSON file\n",
    "def iterate_through_files(directory,operation):\n",
    "        states_list = os.listdir(directory)\n",
    "\n",
    "        #Iterate through states list\n",
    "        for state in states_list:\n",
    "                #Get the state path\n",
    "                state_path = f'{directory}//{state}'\n",
    "                #List all the years\n",
    "                state_year = os.listdir(state_path)\n",
    "                #Iterate through year list\n",
    "                for year in state_year:\n",
    "                        #Get a year path\n",
    "                        year_path = f'{state_path}//{year}'\n",
    "                        #List all the files in the year folder\n",
    "                        filename_list = []\n",
    "                        for (dirpath, dirnames, files) in os.walk(year_path):\n",
    "                                filename_list.extend(files)\n",
    "                                break\n",
    "                        #Iterate for each json file\n",
    "                        for quarter_file in filename_list:\n",
    "                                #Get the file path\n",
    "                                quarter_path = f'{year_path}//{quarter_file}'\n",
    "                                #Extract the quarter from the file name\n",
    "                                quarter = int(Path(quarter_path).stem)\n",
    "                                #Read the json file\n",
    "                                year_json = read_json(quarter_path)\n",
    "                                #Function call for each file to enter it in the data dictionary\n",
    "                                perform_extraction(state,year,quarter,operation,year_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae602e",
   "metadata": {},
   "source": [
    "<h3><center>*********<u>Entry Point of the program</u>*********</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79ef4f",
   "metadata": {},
   "source": [
    "<center>Run all the cell blocks above and the run this to start the process</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3cccb9",
   "metadata": {},
   "source": [
    "<b>Calling the functions to iterate through the directories</b>\n",
    "\n",
    "Here we call the <i><u>iterate_through_files()</u></i> for all the directories.\n",
    "Then the extracted data is saved into the data dictionaries.\n",
    "After that the dictionary is saved to the csv file\n",
    "This is the main entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d30efda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function calls for iterating through the files\n",
    "\n",
    "#Aggregated insurance\n",
    "iterate_through_files(agg_insurance_dir,'agg_insurance')\n",
    "save_to_csv(agg_insurance_data,'Aggregated_insurance_table.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
